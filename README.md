# ğŸ¶ Musical LLM â€“ AI-Powered Raag and Audio Analysis Toolkit

**A Multimodal Music Analysis Toolkit for Indian Classical and Western Music Traditions using AI**

---

## ğŸ§  Overview

**Musical LLM** is an AI-powered music analysis toolkit designed to bridge the gap between computational musicology and Indian/Western classical music traditions. It focuses on analyzing `.wav`, `.mp3`, and MIDI files to extract musical insights including:

* Raag identification (Hindustani Classical)
* Chord progression detection (Western theory)
* Key, tempo, scale, and rhythmic analysis
* MIDI generation and music staff notation
* Instrument separation and symbolic music output

This project aims to serve musicians, composers, educators, and AI researchers who are looking to fuse traditional musical analysis with modern AI techniques.

---

## ğŸ¯ Key Features

### ğŸ”€ Audio Source Separation

* Uses **Spleeter** to isolate vocals, drums, and instrumental tracks.
* Focuses particularly on the **instrument track** to extract more accurate melodic information for MIDI generation.

### ğŸ¼ Symbolic Music Generation

* Generates **MIDI files** using `pretty_midi`
* Converts analyzed features into **Western staff notation** using `music21`

### ğŸµ Indian Classical Analysis

* **Detects the root note (Sa)** and estimates the **scale/raag**
* Compares melodic structure against known **Hindustani Raags** to predict the most likely Raag
* Identifies **rhythmic cycles** (Taal/Tala) based on tempo and beat patterns

### ğŸ¹ Western Classical Analysis

* Detects **key signature**, **chord progressions**, and **harmonic structure**
* Estimates **time signature** and rhythm patterns

### ğŸ§‘â€ğŸ¤ User Interaction

* **Gradio interface** provides a clean, browser-based UI for users to upload files and view results
* Displays waveforms, MIDI previews, and sheet music interactively

---

## ğŸ§° Technology Stack & Dependencies

* **Python 3.10+**
* [`librosa`](https://librosa.org/) â€“ audio feature extraction
* [`Spleeter`](https://github.com/deezer/spleeter) â€“ source separation
* [`music21`](https://web.mit.edu/music21/) â€“ music theory and notation
* [`pretty_midi`](https://github.com/craffel/pretty-midi) â€“ MIDI file manipulation
* [`gradio`](https://gradio.app/) â€“ browser-based UI
* **FFmpeg** â€“ required backend for audio I/O
* **TensorFlow / PyTorch** â€“ (for Spleeter and potential deep models)

---

## ğŸš€ Future Directions

This toolkit is designed as a foundation and will continue evolving into a multimodal, multilingual music analysis platform. Planned enhancements include:

### ğŸ–¼ï¸ Sheet Music (Image) Support

* Integrate **Optical Music Recognition (OMR)** using models like:

  * [`naver-clova-ix/donut-base-finetuned-omr`](https://huggingface.co/naver-clova-ix/donut-base-finetuned-omr)
  * Audiveris (open-source OMR)

### ğŸ—£ï¸ Text & Voice Notes as Input

* Use **Whisper** to transcribe voice memos or sung examples
* Feed transcribed text into an **LLM** (e.g., Mistral, LLaMA) for explanation, discussion, or generation of musical instructions

### ğŸº Carnatic Classical Expansion

* Add support for **Carnatic Ragas**, **Gamaka analysis**, and **Tala system** recognition
* Use **custom-trained models** or rule-based logic for more accurate Carnatic analysis

### ğŸ’¬ LLM Integration

* Use `transformers` to power a music theory assistant that can explain results, generate new compositions, or translate theory across music systems

---

## ğŸ“‚ Project Structure

```
musical-llm/
â”œâ”€â”€ audio_analysis.py         # Main entry point
â”œâ”€â”€ separated_audio/          # Output from Spleeter
â”œâ”€â”€ midi_output/              # Generated MIDI files
â”œâ”€â”€ notation_output/          # Sheet music files
â”œâ”€â”€ models/                   # Future ML model files
â””â”€â”€ gradio_ui.py              # UI app
```

---

## ğŸ“Œ Use Cases

* ğŸ“ **Music Students** â€“ Analyze ragas, notations, and rhythms from recordings
* ğŸ§ **AI & ML Researchers** â€“ Study audio/music processing with deep learning
* ğŸ§‘â€ğŸ» **Fusion Composers** â€“ Convert raags into MIDI for orchestration
* ğŸªª **Educators** â€“ Use staff notation + audio separation in classrooms
* ğŸ¤ **Performers** â€“ Visualize and practice from their own recordings

---

## ğŸ› ï¸ Installation & Usage

### ğŸ”§ Prerequisites

Make sure you have:

* Python 3.10+
* `ffmpeg` installed and added to your system `PATH`

### ğŸ“¦ Install dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install librosa music21 pretty_midi spleeter gradio transformers
```

### â–¶ï¸ Run the Application

```bash
python gradio_ui.py
```

Then open your browser to view the interface and upload your audio files.

---

## ğŸŒ Related Resources

* [Raag Recognition Papers](https://arxiv.org/abs/1703.08115)
* [Carnatic Music Analysis Tools](https://compmusic.upf.edu/)
* [OMR for Indian Music](https://audiveris.github.io/)
* [Hugging Face Music Models](https://huggingface.co/models?pipeline_tag=audio)

---

## ğŸ¤ Contributing

Contributions, feature suggestions, and dataset links are welcome! Please open an issue or pull request with details.

---

## ğŸ“œ License

This project is under no license but have a Keen Ideology to use for all.

---
